{
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# Introduction  Notebook\n\nEstimated time needed: **10** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Acquire data in various ways\n*   Obtain insights from data with Pandas library\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Table of Contents</h2>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><a href=\"https://#data_acquisition\">Data Acquisition</a>\n    <li><a href=\"https://#basic_insight\">Basic Insight of Dataset</a></li>\n</ol>\n\n</div>\n<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h1 id=\"data_acquisition\">Data Acquisition</h1>\n<p>\nThere are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n\nIn this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n\nIn our case, the Automobile Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n\n<ul>\n    <li>Data source: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data</a></li>\n    <li>Data type: csv</li>\n</ul>\nThe Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "you are running the lab in your  browser, so we will install the libraries using `piplite`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#you are running the lab in your  browser, so we will install the libraries using ``piplite``\nimport piplite\nimport micropip\nawait piplite.install(['pandas'])\nawait piplite.install(['matplotlib'])\nawait piplite.install(['scipy'])\nawait piplite.install(['seaborn'])\nawait micropip.install(['ipywidgets'],keep_going=True)\nawait micropip.install(['tqdm'],keep_going=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#install specific version of libraries used in  lab\n#! mamba install pandas==1.3.3  -y\n#! mamba install numpy=1.21.2 -y",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# import pandas library\nimport pandas as pd\nimport numpy as np",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "This function will download the dataset into your browser\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#This function will download the dataset into your browser \n\nfrom pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read Data</h2>\n<p>\nWe use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n\nBecause the data does not include headers, we can add an argument <code>headers = None</code> inside the <code>read_csv()</code> method so that pandas will not automatically set the first row as a header.<br>\n\nYou can also assign the dataset to any variable you create.\n\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\"",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "you will need to download the dataset; if you are running locally, please comment out the following\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#you will need to download the dataset; if you are running locally, please comment out the following \nawait download(path, \"auto.csv\")\npath=\"auto.csv\"",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Import pandas library\nimport pandas as pd\n\n# Read the online file by the URL provides above, and assign it to variable \"df\"\n\ndf = pd.read_csv(path, header=None)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe, where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\") \ndf.head(5)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #1: </h1>\n<b>Check the bottom 10 rows of data frame \"df\".</b>\n</div>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute \n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```python\nprint(\"The last 10 rows of the dataframe\\n\")\ndf.tail(10)\n```\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h3>Add Headers</h3>\n<p>\nTake a look at our dataset. Pandas automatically set the header with an integer starting from 0.\n</p>\n<p>\nTo better describe our data, we can introduce a header. This information is available at:  <a href=\"https://archive.ics.uci.edu/ml/datasets/Automobile?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/datasets/Automobile</a>.\n</p>\n<p>\nThus, we have to add headers manually.\n</p>\n<p>\nFirst, we create a list \"headers\" that include all column names in order.\nThen, we use <code>dataframe.columns = headers</code> to replace the headers with the list we created.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# create headers list\nheaders = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\nprint(\"headers\\n\", headers)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We replace headers and recheck our dataframe:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.columns = headers\ndf.head(10)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We need to replace the \"?\" symbol with NaN so the dropna() can remove the missing values:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df1=df.replace('?',np.NaN)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We can drop missing values along the column \"price\" as follows:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df=df1.dropna(subset=[\"price\"], axis=0)\ndf.head(20)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now, we have successfully read the raw dataset and added the correct headers into the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #2: </h1>\n<b>Find the name of the columns of the dataframe.</b>\n</div>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute \n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```python\nprint(df.columns)\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Save Dataset</h2>\n<p>\nCorrespondingly, Pandas enables us to save the dataset to csv. By using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n</p>\n<p>\nFor example, if you would save the dataframe <b>df</b> as <b>automobile.csv</b> to your local machine, you may use the syntax below, where <code>index = False</code> means the row names will not be written.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "df.to_csv(\"automobile.csv\", index=False)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can also read and save other file formats. We can use similar functions like **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read/Save Other Data Formats</h2>\n\n| Data Formate |        Read       |            Save |\n| ------------ | :---------------: | --------------: |\n| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n| json         |  `pd.read_json()` |  `df.to_json()` |\n| excel        | `pd.read_excel()` | `df.to_excel()` |\n| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n| ...          |        ...        |             ... |\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h1 id=\"basic_insight\">Basic Insight of Dataset</h1>\n<p>\nAfter reading data into Pandas dataframe, it is time for us to explore the dataset.<br>\n\nThere are several ways to obtain essential insights of the data to help us better understand our dataset.\n\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Data Types</h2>\n<p>\nData has a variety of types.<br>\n\nThe main types stored in Pandas dataframes are <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.dtypes\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "A series with the data type of each column is returned.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# check the data type of data frame \"df\" by .dtypes\nprint(df.dtypes)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<p>\nAs shown above, it is clear to see that the data type of \"symboling\" and \"curb-weight\" are <code>int64</code>, \"normalized-losses\" is <code>object</code>, and \"wheel-base\" is <code>float64</code>, etc.\n</p>\n<p>\nThese data types can be changed; we will learn how to accomplish this in a later module.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Describe</h2>\nIf we would like to get a statistical summary of each column e.g. count, column mean value, column standard deviation, etc., we use the describe method:\n",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "dataframe.describe()",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This method will provide various summary statistics, excluding <code>NaN</code> (Not a Number) values.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.describe()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<p>\nThis shows the statistical summary of all numeric-typed (int, float) columns.<br>\n\nFor example, the attribute \"symboling\" has 205 counts, the mean value of this column is 0.83, the standard deviation is 1.25, the minimum value is -2, 25th percentile is 0, 50th percentile is 1, 75th percentile is 2, and the maximum value is 3. <br>\n\nHowever, what if we would also like to check all the columns including those that are of type object? <br><br>\n\nYou can add an argument <code>include = \"all\"</code> inside the bracket. Let's try it again.\n\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# describe all the columns in \"df\" \ndf.describe(include = \"all\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<p>\nNow it provides the statistical summary of all the columns, including object-typed attributes.<br>\n\nWe can now see how many unique values there, which one is the top value and the frequency of top value in the object-typed columns.<br>\n\nSome values in the table above show as \"NaN\". This is because those numbers are not available regarding a particular column type.<br>\n\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #3: </h1>\n\n<p>\nYou can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3']]</code>\n</p>\n<p>\nWhere \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3'] ].describe()</code>\n</p>\n\nApply the  method to \".describe()\" to the columns 'length' and 'compression-ratio'.\n\n</div>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute \n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```python\ndf[['length', 'compression-ratio']].describe()\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Info</h2>\nAnother method you can use to check your dataset is:\n",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "dataframe.info()",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "It provides a concise summary of your DataFrame.\n\nThis method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# look at the info of \"df\"\ndf.info()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h1>Excellent! You have just completed the  Introduction Notebook!</h1>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Thank you for completing this lab!\n\n## Author\n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">Joseph Santarcangelo</a>\n\n### Other Contributors\n\n<a href=\"https://www.linkedin.com/in/mahdi-noorian-58219234/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">Mahdi Noorian PhD</a>\n\nBahare Talayian\n\nEric Xiao\n\nSteven Dong\n\nParizad\n\nHima Vasudevan\n\n<a href=\"https://www.linkedin.com/in/fiorellawever/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">Fiorella Wenver</a>\n\n<a href=\"https:// https://www.linkedin.com/in/yi-leng-yao-84451275/ \" target=\"_blank\" >Yi Yao</a>.\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                         |\n| ----------------- | ------- | ---------- | ---------------------------------------------------------- |\n| 2022-08-23        | 2.4     | Malika     | Import micropip added and parameter for ipwidgets and tqdm |\n| 2020-10-30        | 2.3     | Lakshmi    | Changed URL of the csv                                     |\n| 2020-09-22        | 2.2     | Nayef      | Added replace() method to remove '?'                       |\n| 2020-09-09        | 2.1     | Lakshmi    | Made changes in info method of dataframe                   |\n| 2020-08-27        | 2.0     | Lavanya    | Moved lab to course repo in GitLab                         |\n\n<hr>\n\n## <h3 align=\"center\"> Â© IBM Corporation 2020. All rights reserved. <h3/>\n",
      "metadata": {}
    }
  ]
}